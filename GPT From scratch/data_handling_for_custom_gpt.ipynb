{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tiny Stories"
      ],
      "metadata": {
        "id": "g0WuiWYPGcp-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "INasUiKdD_2z"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:5%]\")\n",
        "text = dataset[\"text\"]\n",
        "combine_text = \"\\n\".join(text)\n",
        "combine_text[:100]\n",
        "with open(\"TinyStories.txt\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(combine_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WikiText"
      ],
      "metadata": {
        "id": "xTVWpyl1ERqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\",split=\"train\")\n",
        "text = dataset[\"text\"]\n",
        "combine = \"\\n\".join(text)\n",
        "with open(\"wikitext-2-raw-v1.txt\",\"w\",encoding=\"utf8\") as f:\n",
        "  f.write(combine)"
      ],
      "metadata": {
        "id": "eZgUi6eqEQ9-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic + shakespear"
      ],
      "metadata": {
        "id": "quMynbEPGgO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean(text):\n",
        "  # Remove emojis\n",
        "  emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "        \"\\U0001F780-\\U0001F7FF\"  # geometric shapes extended\n",
        "        \"\\U0001F800-\\U0001F8FF\"  # supplemental arrows-C\n",
        "        \"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
        "        \"\\U0001FA00-\\U0001FA6F\"  # chess symbols\n",
        "        \"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
        "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "  text = emoji_pattern.sub(r'', text)\n",
        "  # Remove # and *\n",
        "  text = re.sub(r\"[#*]\", \"\", text)\n",
        "  text = text.lower()\n",
        "  return text\n",
        "\n",
        "with open(\"input.txt\",\"r\") as f:\n",
        "  data = f.read()\n",
        "\n",
        "data = clean(data)\n",
        "\n",
        "with open(\"synthetic_shakspear.txt\",\"w\",encoding=\"utf8\") as f:\n",
        "  f.write(data)"
      ],
      "metadata": {
        "id": "RFGJzwnTE4Hv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"/content/wikitext-2-raw-v1.txt\",\"/content/synthetic_shakspear.txt\"]\n",
        "\n",
        "with open(\"combine.txt\",\"w\",encoding=\"utf8\") as f:\n",
        "  for file_name in files:\n",
        "    with open(file_name,\"r\") as input_file:\n",
        "      f.write(input_file.read())\n",
        "      f.write(\"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "9-Vl67jVGm79"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Qe5F-_tIxPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}